import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader


class Net(torch.nn.Module):
    """
    å®šä¹‰ä¸€ä¸ªç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œ
    ç»§æ‰¿è‡ªtorch.nn.ModuleåŸºç±»ï¼Œæ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å—çš„åŸºç±»
    """

    def __init__(self):
        """
        åˆå§‹åŒ–ç½‘ç»œç»“æ„
        åœ¨è¿™é‡Œå®šä¹‰ç½‘ç»œçš„å„ä¸ªå±‚
        """
        # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œè¿™ä¸€æ­¥æ˜¯å¿…é¡»çš„
        super(Net, self).__init__()

        # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼š
        # è¾“å…¥é€šé“æ•°=1ï¼ˆç°åº¦å›¾åƒï¼‰
        # è¾“å‡ºé€šé“æ•°=10ï¼ˆ10ä¸ªä¸åŒçš„ç‰¹å¾å›¾ï¼‰
        # kernel_size=5ï¼ˆ5x5çš„å·ç§¯æ ¸ï¼‰
        # å¯¹äºMNISTæ•°æ®é›†(28x28)ï¼Œå·ç§¯åçš„å°ºå¯¸å˜ä¸º(28-5+1)x(28-5+1) = 24x24
        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)

        # ç¬¬äºŒä¸ªå·ç§¯å±‚ï¼š
        # è¾“å…¥é€šé“æ•°=10ï¼ˆæ¥è‡ªconv1çš„è¾“å‡ºï¼‰
        # è¾“å‡ºé€šé“æ•°=20ï¼ˆ20ä¸ªä¸åŒçš„ç‰¹å¾å›¾ï¼‰
        # kernel_size=5ï¼ˆ5x5çš„å·ç§¯æ ¸ï¼‰
        # åœ¨ç»è¿‡ç¬¬ä¸€æ¬¡æ± åŒ–åå°ºå¯¸ä¸º12x12ï¼Œå·ç§¯åå˜ä¸º(12-5+1)x(12-5+1) = 8x8
        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)

        # æœ€å¤§æ± åŒ–å±‚ï¼š
        # kernel_size=2ï¼ˆ2x2çš„æ± åŒ–çª—å£ï¼‰
        # ä½œç”¨ï¼šå°†ç‰¹å¾å›¾çš„å°ºå¯¸å‡åŠï¼ŒåŒæ—¶ä¿ç•™æœ€é‡è¦çš„ç‰¹å¾
        # æ¯æ¬¡æ‰§è¡Œåï¼Œç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦éƒ½å‡åŠ
        self.pooling = torch.nn.MaxPool2d(2)

        # å…¨è¿æ¥å±‚ï¼š
        # è¾“å…¥ç‰¹å¾æ•°=320ï¼ˆè®¡ç®—æ–¹æ³•ï¼š20ä¸ªé€šé“ Ã— 4Ã—4çš„ç‰¹å¾å›¾ = 320ï¼‰
        # è¾“å‡ºç‰¹å¾æ•°=10ï¼ˆå¯¹åº”10ä¸ªæ•°å­—ç±»åˆ«ï¼‰
        # å¯¹åº”çš„ç»´åº¦å˜æ¢è¿‡ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š
        # ğ‘˜ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ = 2 Ã— 2
        # (ğ‘ğ‘ğ‘¡ğ‘â„, 20, 8, 8) â†’ ç»è¿‡æ± åŒ– â†’ (ğ‘ğ‘ğ‘¡ğ‘â„, 20, 4, 4) â†’ å±•å¹³ â†’ (ğ‘ğ‘ğ‘¡ğ‘â„, 320)
        self.fc = torch.nn.Linear(320, 10)

    def forward(self, x):
        """
        å®šä¹‰å‰å‘ä¼ æ’­è·¯å¾„
        å‚æ•°xæ˜¯è¾“å…¥æ•°æ®
        """
        # è·å–å½“å‰æ‰¹æ¬¡çš„æ ·æœ¬æ•°é‡
        # xçš„å½¢çŠ¶ä¸º[batch_size, channels, height, width]
        '''
            labels.size(0) è·å– labels å¼ é‡çš„ç¬¬ 0 ç»´çš„å¤§å°ï¼Œä¹Ÿå°±æ˜¯ batch_sizeã€‚
            labels = torch.tensor([1, 2, 0, 1, 2, 1, 0, 2, ...])  # å…± 64 ä¸ªå…ƒç´ 
            print(labels.size(0))  # è¾“å‡º: 64
        '''
        batch_size = x.size(0)

        # ç¬¬ä¸€ä¸ªå·ç§¯å—ï¼šå·ç§¯+æ± åŒ–+ReLUæ¿€æ´»
        # è¾“å…¥ï¼š(batch, 1, 28, 28)ï¼Œå³åŸå§‹å›¾åƒ
        # å·ç§¯åï¼š(batch, 10, 24, 24)
        # æ± åŒ–åï¼š(batch, 10, 12, 12)
        # ReLUåä¿æŒå½¢çŠ¶ä¸å˜ï¼Œä½†æ¿€æ´»äº†éçº¿æ€§ç‰¹æ€§
        x = F.relu(self.pooling(self.conv1(x)))

        # ç¬¬äºŒä¸ªå·ç§¯å—ï¼šå·ç§¯+æ± åŒ–+ReLUæ¿€æ´»
        # è¾“å…¥ï¼š(batch, 10, 12, 12)
        # å·ç§¯åï¼š(batch, 20, 8, 8)
        # æ± åŒ–åï¼š(batch, 20, 4, 4)
        # ReLUåå½¢çŠ¶ä¸å˜
        x = F.relu(self.pooling(self.conv2(x)))

        # å±•å¹³æ“ä½œï¼Œå°†3Dç‰¹å¾å›¾è½¬ä¸º1Då‘é‡
        # è¾“å…¥ï¼š(batch, 20, 4, 4)
        # è¾“å‡ºï¼š(batch, 320)
        # -1è¡¨ç¤ºè‡ªåŠ¨è®¡ç®—è¯¥ç»´åº¦çš„å¤§å°ï¼Œä¿æŒå…ƒç´ æ€»æ•°ä¸å˜
        x = x.view(batch_size, -1)  # flatten

        # å…¨è¿æ¥å±‚ï¼Œè¿›è¡Œæœ€ç»ˆåˆ†ç±»
        # è¾“å…¥ï¼š(batch, 320)
        # è¾“å‡ºï¼š(batch, 10)ï¼Œå¯¹åº”10ä¸ªç±»åˆ«çš„å¾—åˆ†
        x = self.fc(x)

        # è¿”å›æœ€ç»ˆè¾“å‡º
        # æ³¨æ„ï¼šé€šå¸¸ä¸åœ¨è¿™é‡Œåº”ç”¨softmaxï¼Œå› ä¸ºäº¤å‰ç†µæŸå¤±å‡½æ•°ä¼šåœ¨å†…éƒ¨å¤„ç†
        return x


# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = Net()

# ä¸‹è½½å¹¶åŠ è½½ MNIST æ•°æ®é›†
script_dir = os.path.dirname(os.path.abspath(__file__))  # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
data_dir = os.path.join(script_dir, "data")
train_dataset = torchvision.datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)
test_dataset = torchvision.datasets.MNIST(root=data_dir, train=False, transform=transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)


# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®¾ç½®è®¡ç®—è®¾å¤‡
# å¦‚æœæœ‰GPUï¼ˆcuda:0ï¼‰åˆ™ä½¿ç”¨GPUï¼Œå¦åˆ™ä½¿ç”¨CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# åº”è¯¥åœ¨è¿™é‡Œæ·»åŠ ï¼šmodel = model.to(device)ï¼Œå°†æ¨¡å‹ç§»è‡³æŒ‡å®šè®¾å¤‡


def train(epoch):
    """
    è®­ç»ƒä¸€ä¸ªepoch

    å‚æ•°:
    - epoch: å½“å‰è®­ç»ƒçš„è½®æ¬¡
    """
    # ç”¨äºç´¯è®¡æŸå¤±å€¼
    running_loss = 0.0

    # æšä¸¾è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡
    # enumerateè¿”å›ç´¢å¼•å’Œæ•°æ®ï¼Œä»0å¼€å§‹è®¡æ•°
    for batch_idx, data in enumerate(train_loader, 0):
        # è§£åŒ…æ•°æ®ï¼Œå¾—åˆ°è¾“å…¥å’Œç›®æ ‡
        inputs, target = data

        # è¿™é‡Œåº”è¯¥æ·»åŠ è®¾å¤‡è½¬ç§»ï¼š
        # inputs, target = inputs.to(device), target.to(device)

        # æ¸…ç©ºæ¢¯åº¦ç¼“å­˜
        # ä¼˜åŒ–å™¨åœ¨æ¯æ¬¡è¿­ä»£å‰éœ€è¦å°†æ¢¯åº¦æ¸…é›¶ï¼Œå¦åˆ™æ¢¯åº¦ä¼šç´¯åŠ 
        optimizer.zero_grad()

        # å‰å‘ä¼ æ’­ + åå‘ä¼ æ’­ + å‚æ•°æ›´æ–°

        # å‰å‘ä¼ æ’­ï¼šè®¡ç®—æ¨¡å‹çš„é¢„æµ‹è¾“å‡º
        outputs = model(inputs)

        # è®¡ç®—æŸå¤±ï¼šé¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚
        # criterioné€šå¸¸æ˜¯äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œé€‚ç”¨äºåˆ†ç±»é—®é¢˜
        loss = criterion(outputs, target)

        # åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
        loss.backward()

        # å‚æ•°æ›´æ–°ï¼šä½¿ç”¨ä¼˜åŒ–å™¨æ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°
        optimizer.step()

        # ç´¯åŠ æ‰¹æ¬¡æŸå¤±
        running_loss += loss.item()

        # æ¯300ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è®­ç»ƒçŠ¶æ€
        if batch_idx % 300 == 299:
            print('[%d, %5d] loss: %.3f' % (
                epoch + 1,              # å½“å‰epoch
                batch_idx + 1,          # å½“å‰æ‰¹æ¬¡
                running_loss / 2000))   # å¹³å‡æŸå¤±
            # é‡ç½®ç´¯è®¡æŸå¤±
            running_loss = 0.0


def test():
    """
    åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
    """
    # æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æ•°
    correct = 0
    # æ€»æ ·æœ¬æ•°
    total = 0

    # ä½¿ç”¨torch.no_grad()ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    # åœ¨è¯„ä¼°é˜¶æ®µä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œå¯ä»¥èŠ‚çœå†…å­˜å¹¶åŠ é€Ÿè®¡ç®—
    with torch.no_grad():
        # éå†æµ‹è¯•æ•°æ®é›†
        for data in test_loader:
            # è§£åŒ…æ•°æ®
            inputs, target = data

            # åº”è¯¥æ·»åŠ è®¾å¤‡è½¬ç§»ï¼š
            # inputs, target = inputs.to(device), target.to(device)

            # å‰å‘ä¼ æ’­ï¼Œè·å–é¢„æµ‹è¾“å‡º
            outputs = model(inputs)

            # è·å–é¢„æµ‹çš„ç±»åˆ«
            # torch.maxè¿”å›æ¯è¡Œçš„æœ€å¤§å€¼åŠå…¶ç´¢å¼•
            # dim=1è¡¨ç¤ºåœ¨ç¬¬äºŒä¸ªç»´åº¦ï¼ˆç±»åˆ«ç»´åº¦ï¼‰ä¸Šæ±‚æœ€å¤§å€¼
            # è¿”å›å€¼ä¸­ '_' æ˜¯æœ€å¤§å€¼ï¼Œpredictedæ˜¯å¯¹åº”çš„ç´¢å¼•ï¼ˆç±»åˆ«ï¼‰
            _, predicted = torch.max(outputs.data, dim=1)

            # ç´¯åŠ æ€»æ ·æœ¬æ•°
            total += target.size(0)

            # ç´¯åŠ æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬æ•°
            # (predicted == target)åˆ›å»ºä¸€ä¸ªå¸ƒå°”å¼ é‡
            # .sum()è®¡ç®—Trueçš„æ•°é‡
            # .item()å°†å•å…ƒç´ å¼ é‡è½¬æ¢ä¸ºPythonæ•°å€¼
            correct += (predicted == target).sum().item()

    # æ‰“å°å‡†ç¡®ç‡
    print('Accuracy on test set: %d %% [%d/%d]' % (
        100 * correct / total,  # å‡†ç¡®ç‡ç™¾åˆ†æ¯”
        correct,                # æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æ•°
        total))                 # æ€»æ ·æœ¬æ•°

# åœ¨ä¸»ç¨‹åºä¸­åº”è¯¥æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
# 1. å®šä¹‰æŸå¤±å‡½æ•°ï¼šcriterion = nn.CrossEntropyLoss()
# 2. å®šä¹‰ä¼˜åŒ–å™¨ï¼šoptimizer = torch.optim.SGD(model.parameters(), lr=0.01)
# 3. è®­ç»ƒå¾ªç¯ï¼šfor epoch in range(10): train(epoch)
# 4. æµ‹è¯•æ¨¡å‹ï¼štest()
